{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/17/1999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/14/2008</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/09/2013</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/02/2012</td>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>05/09/2009</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  ...  \\\n",
       "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2  ...   \n",
       "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1  ...   \n",
       "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2  ...   \n",
       "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4  ...   \n",
       "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2  ...   \n",
       "\n",
       "   P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0  3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
       "1  3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
       "2  3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
       "3  7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
       "4  3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['Id','Open Date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  City Group Type  P1   P2   P3   P4  P5  P6  P7  ...  P29  P30  \\\n",
       "0    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2   2   5  ...  3.0    5   \n",
       "1      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1   2   5  ...  3.0    0   \n",
       "2  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2   3   5  ...  3.0    0   \n",
       "3       Tokat       Other   IL   6  4.5  6.0  6.0   4   4  10  ...  7.5   25   \n",
       "4   Gaziantep       Other   IL   3  4.0  3.0  4.0   2   2   5  ...  3.0    5   \n",
       "\n",
       "   P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    3    4    5    5    4    3    4  5653753.0  \n",
       "1    0    0    0    0    0    0    0  6923131.0  \n",
       "2    0    0    0    0    0    0    0  2055379.0  \n",
       "3   12   10    6   18   12   12    6  2675511.0  \n",
       "4    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['City']= label_encoder.fit_transform(train['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['City Group']= label_encoder.fit_transform(train['City Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Type']= label_encoder.fit_transform(train['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Type']= label_encoder.fit_transform(test['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['City']= label_encoder.fit_transform(test['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['City Group']= label_encoder.fit_transform(test['City Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  City Group  Type  P1   P2   P3   P4  P5  P6  P7  ...  P29  P30  P31  \\\n",
       "0    31           0     2   4  5.0  4.0  4.0   2   2   5  ...  3.0    5    3   \n",
       "1     3           0     1   4  5.0  4.0  4.0   1   2   5  ...  3.0    0    0   \n",
       "2    10           1     2   2  4.0  2.0  5.0   2   3   5  ...  3.0    0    0   \n",
       "3    28           1     2   6  4.5  6.0  6.0   4   4  10  ...  7.5   25   12   \n",
       "4    14           1     2   3  4.0  3.0  4.0   2   2   5  ...  3.0    5    1   \n",
       "\n",
       "   P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    4    5    5    4    3    4  5653753.0  \n",
       "1    0    0    0    0    0    0  6923131.0  \n",
       "2    0    0    0    0    0    0  2055379.0  \n",
       "3   10    6   18   12   12    6  2675511.0  \n",
       "4    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01/22/2011</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/18/2011</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10/30/2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>05/06/2013</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>07/31/2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Open Date  City  City Group  Type  P1   P2   P3   P4  P5  ...  P28  \\\n",
       "0   0  01/22/2011    38           1     1   1  4.0  4.0  4.0   1  ...  2.0   \n",
       "1   1  03/18/2011    27           1     2   3  4.0  4.0  4.0   2  ...  1.0   \n",
       "2   2  10/30/2013     3           0     1   3  4.0  4.0  4.0   2  ...  2.0   \n",
       "3   3  05/06/2013    26           1     2   2  4.0  4.0  4.0   2  ...  2.0   \n",
       "4   4  07/31/2013     1           1     1   2  4.0  4.0  4.0   1  ...  5.0   \n",
       "\n",
       "   P29  P30  P31  P32  P33  P34  P35  P36  P37  \n",
       "0  3.0    0    0    0    0    0    0    0    0  \n",
       "1  3.0    0    0    0    0    0    0    0    0  \n",
       "2  3.0    0    0    0    0    0    0    0    0  \n",
       "3  3.0    0    4    0    0    0    0    0    0  \n",
       "4  3.0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(['Id','Open Date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>...</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  City Group  Type  P1   P2   P3   P4  P5  P6  P7  ...  P28  P29  P30  \\\n",
       "0    38           1     1   1  4.0  4.0  4.0   1   2   5  ...  2.0  3.0    0   \n",
       "1    27           1     2   3  4.0  4.0  4.0   2   2   5  ...  1.0  3.0    0   \n",
       "2     3           0     1   3  4.0  4.0  4.0   2   2   5  ...  2.0  3.0    0   \n",
       "3    26           1     2   2  4.0  4.0  4.0   2   3   5  ...  2.0  3.0    0   \n",
       "4     1           1     1   2  4.0  4.0  4.0   1   2   5  ...  5.0  3.0    0   \n",
       "\n",
       "   P31  P32  P33  P34  P35  P36  P37  \n",
       "0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3    4    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  City Group  Type  P1   P2   P3   P4  P5  P6  P7  ...  P29  P30  P31  \\\n",
       "0    31           0     2   4  5.0  4.0  4.0   2   2   5  ...  3.0    5    3   \n",
       "1     3           0     1   4  5.0  4.0  4.0   1   2   5  ...  3.0    0    0   \n",
       "2    10           1     2   2  4.0  2.0  5.0   2   3   5  ...  3.0    0    0   \n",
       "3    28           1     2   6  4.5  6.0  6.0   4   4  10  ...  7.5   25   12   \n",
       "4    14           1     2   3  4.0  3.0  4.0   2   2   5  ...  3.0    5    1   \n",
       "\n",
       "   P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    4    5    5    4    3    4  5653753.0  \n",
       "1    0    0    0    0    0    0  6923131.0  \n",
       "2    0    0    0    0    0    0  2055379.0  \n",
       "3   10    6   18   12   12    6  2675511.0  \n",
       "4    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =train.drop(['revenue'],axis=1)\n",
    "y =train['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>...</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  City Group  Type  P1   P2   P3   P4  P5  P6  P7  ...  P28  P29  P30  \\\n",
       "0    31           0     2   4  5.0  4.0  4.0   2   2   5  ...  2.0  3.0    5   \n",
       "1     3           0     1   4  5.0  4.0  4.0   1   2   5  ...  3.0  3.0    0   \n",
       "2    10           1     2   2  4.0  2.0  5.0   2   3   5  ...  1.0  3.0    0   \n",
       "3    28           1     2   6  4.5  6.0  6.0   4   4  10  ...  2.5  7.5   25   \n",
       "4    14           1     2   3  4.0  3.0  4.0   2   2   5  ...  1.0  3.0    5   \n",
       "\n",
       "   P31  P32  P33  P34  P35  P36  P37  \n",
       "0    3    4    5    5    4    3    4  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3   12   10    6   18   12   12    6  \n",
       "4    1    3    2    3    4    3    3  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctree = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05319149, 0.0106383 , 0.0106383 , 0.03191489, 0.0212766 ,\n",
       "       0.03191489, 0.03191489, 0.06382979, 0.03191489, 0.0106383 ,\n",
       "       0.0212766 , 0.03191489, 0.04255319, 0.05319149, 0.0212766 ,\n",
       "       0.        , 0.0212766 , 0.0106383 , 0.0212766 , 0.0106383 ,\n",
       "       0.        , 0.04255319, 0.05319149, 0.06382979, 0.04255319,\n",
       "       0.04255319, 0.0212766 , 0.0212766 , 0.0106383 , 0.        ,\n",
       "       0.04255319, 0.06382979, 0.0106383 , 0.        , 0.        ,\n",
       "       0.        , 0.0106383 , 0.        , 0.0106383 , 0.03191489])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P29</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P21</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P5</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P20</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P11</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P10</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P28</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P23</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P22</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P19</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>P37</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P9</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P6</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P4</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P25</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P8</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P24</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P12</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P16</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P14</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Group</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P36</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>P34</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P30</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P7</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P26</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P15</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P17</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P27</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col       imp\n",
       "31         P29  6.382979\n",
       "23         P21  6.382979\n",
       "7           P5  6.382979\n",
       "0         City  5.319149\n",
       "22         P20  5.319149\n",
       "13         P11  5.319149\n",
       "12         P10  4.255319\n",
       "30         P28  4.255319\n",
       "25         P23  4.255319\n",
       "24         P22  4.255319\n",
       "21         P19  4.255319\n",
       "39         P37  3.191489\n",
       "11          P9  3.191489\n",
       "8           P6  3.191489\n",
       "3           P1  3.191489\n",
       "5           P3  3.191489\n",
       "6           P4  3.191489\n",
       "27         P25  2.127660\n",
       "10          P8  2.127660\n",
       "4           P2  2.127660\n",
       "26         P24  2.127660\n",
       "14         P12  2.127660\n",
       "18         P16  2.127660\n",
       "16         P14  2.127660\n",
       "1   City Group  1.063830\n",
       "38         P36  1.063830\n",
       "36         P34  1.063830\n",
       "32         P30  1.063830\n",
       "2         Type  1.063830\n",
       "9           P7  1.063830\n",
       "28         P26  1.063830\n",
       "17         P15  1.063830\n",
       "19         P17  1.063830\n",
       "29         P27  0.000000\n",
       "15         P13  0.000000\n",
       "33         P31  0.000000\n",
       "34         P32  0.000000\n",
       "35         P33  0.000000\n",
       "37         P35  0.000000\n",
       "20         P18  0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame()\n",
    "feature_imp['col']=x.columns\n",
    "feature_imp['imp']=ctree.feature_importances_*100\n",
    "feature_imp.sort_values('imp',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtree = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05319149, 0.0106383 , 0.0106383 , 0.03191489, 0.0212766 ,\n",
       "       0.03191489, 0.03191489, 0.06382979, 0.03191489, 0.0106383 ,\n",
       "       0.0212766 , 0.03191489, 0.04255319, 0.05319149, 0.0212766 ,\n",
       "       0.        , 0.0212766 , 0.0106383 , 0.0212766 , 0.0106383 ,\n",
       "       0.        , 0.04255319, 0.05319149, 0.06382979, 0.04255319,\n",
       "       0.04255319, 0.0212766 , 0.0212766 , 0.0106383 , 0.        ,\n",
       "       0.04255319, 0.06382979, 0.0106383 , 0.        , 0.        ,\n",
       "       0.        , 0.0106383 , 0.        , 0.0106383 , 0.03191489])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P29</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P21</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P5</td>\n",
       "      <td>6.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>P20</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P11</td>\n",
       "      <td>5.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P10</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>P28</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>P23</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P22</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>P19</td>\n",
       "      <td>4.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>P37</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P9</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P6</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P4</td>\n",
       "      <td>3.191489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>P25</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P8</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>P24</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P12</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>P16</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P14</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Group</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P36</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>P34</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P30</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P7</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P26</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>P15</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>P17</td>\n",
       "      <td>1.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>P27</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>P18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           col       imp\n",
       "31         P29  6.382979\n",
       "23         P21  6.382979\n",
       "7           P5  6.382979\n",
       "0         City  5.319149\n",
       "22         P20  5.319149\n",
       "13         P11  5.319149\n",
       "12         P10  4.255319\n",
       "30         P28  4.255319\n",
       "25         P23  4.255319\n",
       "24         P22  4.255319\n",
       "21         P19  4.255319\n",
       "39         P37  3.191489\n",
       "11          P9  3.191489\n",
       "8           P6  3.191489\n",
       "3           P1  3.191489\n",
       "5           P3  3.191489\n",
       "6           P4  3.191489\n",
       "27         P25  2.127660\n",
       "10          P8  2.127660\n",
       "4           P2  2.127660\n",
       "26         P24  2.127660\n",
       "14         P12  2.127660\n",
       "18         P16  2.127660\n",
       "16         P14  2.127660\n",
       "1   City Group  1.063830\n",
       "38         P36  1.063830\n",
       "36         P34  1.063830\n",
       "32         P30  1.063830\n",
       "2         Type  1.063830\n",
       "9           P7  1.063830\n",
       "28         P26  1.063830\n",
       "17         P15  1.063830\n",
       "19         P17  1.063830\n",
       "29         P27  0.000000\n",
       "15         P13  0.000000\n",
       "33         P31  0.000000\n",
       "34         P32  0.000000\n",
       "35         P33  0.000000\n",
       "37         P35  0.000000\n",
       "20         P18  0.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame()\n",
    "feature_imp['col']=x.columns\n",
    "feature_imp['imp']=ctree.feature_importances_*100\n",
    "feature_imp.sort_values('imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x.drop(['P9','P27','P16','P7','P32','P17','P34','P33','P6','P35','P36','P26','P25','P24','P37','P10','P14'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['P9' 'P27' 'P16' 'P7' 'P32' 'P17' 'P34' 'P33' 'P6' 'P35' 'P36' 'P26'\\n 'P25' 'P24' 'P37' 'P10' 'P14'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-d89f63f48fbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'P9'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P27'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P16'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P7'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P32'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P17'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P34'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P33'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P6'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P35'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P36'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P26'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P25'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P24'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P37'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P14'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['P9' 'P27' 'P16' 'P7' 'P32' 'P17' 'P34' 'P33' 'P6' 'P35' 'P36' 'P26'\\n 'P25' 'P24' 'P37' 'P10' 'P14'] not found in axis\""
     ]
    }
   ],
   "source": [
    "test=test.drop(['P9','P27','P16','P7','P32','P17','P34','P33','P6','P35','P36','P26','P25','P24','P37','P10','P14'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P8</th>\n",
       "      <th>P11</th>\n",
       "      <th>...</th>\n",
       "      <th>P18</th>\n",
       "      <th>P19</th>\n",
       "      <th>P20</th>\n",
       "      <th>P21</th>\n",
       "      <th>P22</th>\n",
       "      <th>P23</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   City  City Group  Type  P1   P2   P3   P4  P5  P8  P11  ...  P18  P19  P20  \\\n",
       "0    31           0     2   4  5.0  4.0  4.0   2   4    3  ...    4    5    4   \n",
       "1     3           0     1   4  5.0  4.0  4.0   1   5    1  ...    0    3    2   \n",
       "2    10           1     2   2  4.0  2.0  5.0   2   5    2  ...    0    1    1   \n",
       "3    28           1     2   6  4.5  6.0  6.0   4   8    8  ...   12   20   12   \n",
       "4    14           1     2   3  4.0  3.0  4.0   2   5    2  ...    4    2    2   \n",
       "\n",
       "   P21  P22  P23  P28  P29  P30  P31  \n",
       "0    1    3    3  2.0  3.0    5    3  \n",
       "1    1    3    2  3.0  3.0    0    0  \n",
       "2    1    1    1  1.0  3.0    0    0  \n",
       "3    6    1   10  2.5  7.5   25   12  \n",
       "4    1    2    1  1.0  3.0    5    1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "lable=preprocessing.MinMaxScaler()\n",
    "new_x=lable.fit_transform(x1)\n",
    "cols=x1.columns\n",
    "x_new=pd.DataFrame(new_x,columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalary=preprocessing.MinMaxScaler()\n",
    "y_new=scalary.fit_transform(y1.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P8</th>\n",
       "      <th>P11</th>\n",
       "      <th>...</th>\n",
       "      <th>P18</th>\n",
       "      <th>P19</th>\n",
       "      <th>P20</th>\n",
       "      <th>P21</th>\n",
       "      <th>P22</th>\n",
       "      <th>P23</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.848485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.424242</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.787879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.696970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.060606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.151515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.242424</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.878788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  City Group  Type        P1        P2        P3        P4  \\\n",
       "0    0.939394         0.0   1.0  0.272727  0.615385  0.533333  0.222222   \n",
       "1    0.090909         0.0   0.5  0.272727  0.615385  0.533333  0.222222   \n",
       "2    0.303030         1.0   1.0  0.090909  0.461538  0.266667  0.444444   \n",
       "3    0.848485         1.0   1.0  0.454545  0.538462  0.800000  0.666667   \n",
       "4    0.424242         1.0   1.0  0.181818  0.461538  0.400000  0.222222   \n",
       "5    0.090909         0.0   0.5  0.454545  0.769231  0.600000  1.000000   \n",
       "6    0.939394         0.0   1.0  0.090909  0.307692  0.533333  0.222222   \n",
       "7    0.939394         0.0   1.0  0.272727  0.615385  0.533333  0.444444   \n",
       "8    0.030303         1.0   1.0  0.000000  0.000000  0.533333  0.222222   \n",
       "9    0.333333         1.0   1.0  0.454545  0.538462  0.800000  1.000000   \n",
       "10   0.575758         1.0   0.5  0.727273  0.769231  0.800000  0.666667   \n",
       "11   0.939394         0.0   1.0  0.090909  0.461538  0.533333  0.222222   \n",
       "12   0.090909         0.0   1.0  0.090909  0.153846  0.533333  0.222222   \n",
       "13   0.939394         0.0   0.5  0.272727  0.615385  0.533333  0.222222   \n",
       "14   0.242424         1.0   0.5  0.090909  0.153846  0.533333  0.222222   \n",
       "15   0.939394         0.0   1.0  1.000000  1.000000  0.800000  0.666667   \n",
       "16   0.939394         0.0   0.5  0.181818  0.615385  0.533333  0.222222   \n",
       "17   0.939394         0.0   0.5  0.090909  0.461538  0.533333  0.444444   \n",
       "18   0.969697         0.0   1.0  0.272727  0.615385  0.533333  0.000000   \n",
       "19   0.757576         1.0   1.0  0.090909  0.461538  0.533333  0.222222   \n",
       "20   0.363636         1.0   1.0  0.181818  0.461538  0.533333  0.222222   \n",
       "21   0.939394         0.0   0.5  0.363636  0.615385  0.533333  0.222222   \n",
       "22   0.545455         1.0   0.5  0.727273  0.769231  0.800000  0.666667   \n",
       "23   0.757576         1.0   0.5  0.090909  0.461538  0.533333  0.222222   \n",
       "24   0.939394         0.0   1.0  0.363636  0.615385  0.400000  0.444444   \n",
       "25   0.393939         1.0   0.5  0.272727  0.461538  0.666667  0.444444   \n",
       "26   0.090909         0.0   1.0  0.181818  0.615385  0.533333  0.444444   \n",
       "27   0.242424         1.0   0.5  0.272727  0.615385  0.533333  0.000000   \n",
       "28   0.939394         0.0   1.0  0.272727  0.615385  0.533333  0.222222   \n",
       "29   0.090909         0.0   0.5  0.000000  0.000000  0.533333  0.222222   \n",
       "..        ...         ...   ...       ...       ...       ...       ...   \n",
       "107  0.787879         1.0   1.0  0.272727  0.461538  0.533333  0.222222   \n",
       "108  0.696970         1.0   0.5  0.000000  0.153846  0.666667  0.222222   \n",
       "109  0.090909         0.0   0.5  0.090909  0.461538  0.400000  0.444444   \n",
       "110  0.060606         1.0   1.0  0.454545  0.307692  0.800000  0.666667   \n",
       "111  0.636364         1.0   0.5  0.090909  0.307692  0.533333  0.222222   \n",
       "112  0.939394         0.0   1.0  0.272727  0.615385  0.666667  0.222222   \n",
       "113  0.818182         1.0   0.5  0.181818  0.461538  0.533333  0.222222   \n",
       "114  0.393939         1.0   1.0  0.272727  0.615385  0.666667  0.222222   \n",
       "115  0.939394         0.0   1.0  0.454545  0.538462  0.800000  0.666667   \n",
       "116  0.969697         0.0   0.5  0.090909  0.461538  0.533333  0.222222   \n",
       "117  0.090909         0.0   1.0  0.181818  0.615385  0.533333  0.444444   \n",
       "118  0.939394         0.0   1.0  1.000000  1.000000  1.000000  0.333333   \n",
       "119  0.939394         0.0   1.0  0.272727  0.615385  0.533333  0.222222   \n",
       "120  0.151515         1.0   0.5  0.090909  0.307692  0.533333  0.222222   \n",
       "121  0.969697         0.0   0.5  0.090909  0.461538  0.533333  0.222222   \n",
       "122  0.939394         0.0   1.0  1.000000  1.000000  0.800000  1.000000   \n",
       "123  0.212121         1.0   0.5  0.000000  0.000000  0.533333  0.000000   \n",
       "124  0.090909         0.0   0.0  0.000000  0.307692  0.000000  0.444444   \n",
       "125  0.878788         1.0   1.0  0.727273  0.769231  0.800000  0.666667   \n",
       "126  0.454545         1.0   1.0  0.181818  0.307692  0.533333  0.222222   \n",
       "127  0.242424         1.0   0.5  0.181818  0.461538  0.533333  0.222222   \n",
       "128  0.090909         0.0   0.5  0.090909  0.461538  0.533333  0.222222   \n",
       "129  0.393939         1.0   0.5  0.272727  0.615385  0.666667  0.222222   \n",
       "130  0.727273         1.0   0.5  0.181818  0.461538  0.400000  0.222222   \n",
       "131  0.090909         0.0   0.5  0.181818  0.461538  0.533333  0.444444   \n",
       "132  0.878788         1.0   0.5  0.090909  0.307692  0.400000  0.444444   \n",
       "133  0.969697         0.0   0.5  0.272727  0.615385  0.533333  0.222222   \n",
       "134  0.545455         1.0   0.5  0.181818  0.461538  0.533333  0.222222   \n",
       "135  0.939394         0.0   0.5  0.272727  0.615385  0.533333  0.444444   \n",
       "136  0.939394         0.0   0.5  0.272727  0.615385  0.400000  0.444444   \n",
       "\n",
       "           P5        P8       P11  ...       P18       P19       P20  \\\n",
       "0    0.142857  0.333333  0.222222  ...  0.333333  0.166667  0.214286   \n",
       "1    0.000000  0.444444  0.000000  ...  0.000000  0.083333  0.071429   \n",
       "2    0.142857  0.444444  0.111111  ...  0.000000  0.000000  0.000000   \n",
       "3    0.428571  0.777778  0.777778  ...  1.000000  0.791667  0.785714   \n",
       "4    0.142857  0.444444  0.111111  ...  0.333333  0.041667  0.071429   \n",
       "5    1.000000  0.777778  1.000000  ...  0.000000  0.166667  0.357143   \n",
       "6    0.000000  0.444444  0.111111  ...  0.333333  0.041667  0.214286   \n",
       "7    0.142857  0.333333  0.333333  ...  0.000000  0.083333  0.285714   \n",
       "8    0.000000  0.444444  0.000000  ...  0.333333  0.000000  0.000000   \n",
       "9    0.714286  1.000000  0.111111  ...  0.000000  1.000000  0.142857   \n",
       "10   0.428571  0.777778  0.777778  ...  0.000000  1.000000  1.000000   \n",
       "11   0.142857  0.444444  0.111111  ...  0.333333  0.041667  0.285714   \n",
       "12   0.142857  0.333333  0.222222  ...  0.000000  0.083333  0.214286   \n",
       "13   0.000000  0.444444  0.111111  ...  0.000000  0.083333  0.214286   \n",
       "14   0.000000  0.444444  0.111111  ...  0.000000  0.083333  0.142857   \n",
       "15   0.142857  1.000000  0.333333  ...  1.000000  0.375000  0.571429   \n",
       "16   0.142857  0.333333  0.222222  ...  0.000000  0.000000  0.214286   \n",
       "17   0.000000  0.333333  0.222222  ...  0.000000  0.000000  0.000000   \n",
       "18   0.000000  0.444444  0.111111  ...  0.250000  0.125000  0.285714   \n",
       "19   0.142857  0.444444  0.000000  ...  0.000000  0.041667  0.000000   \n",
       "20   0.142857  0.333333  0.222222  ...  0.333333  0.166667  0.285714   \n",
       "21   0.142857  0.333333  0.333333  ...  0.000000  0.125000  0.285714   \n",
       "22   0.428571  1.000000  0.111111  ...  0.000000  0.583333  0.785714   \n",
       "23   0.142857  0.222222  0.444444  ...  0.000000  0.041667  0.071429   \n",
       "24   0.142857  0.444444  0.111111  ...  0.333333  0.166667  0.285714   \n",
       "25   0.142857  0.444444  0.111111  ...  0.000000  0.083333  0.000000   \n",
       "26   0.142857  0.222222  0.444444  ...  0.333333  0.166667  0.285714   \n",
       "27   0.000000  0.333333  0.333333  ...  0.000000  0.166667  0.285714   \n",
       "28   0.000000  0.444444  0.111111  ...  0.333333  0.166667  0.285714   \n",
       "29   0.142857  0.333333  0.444444  ...  0.000000  0.000000  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "107  0.000000  0.333333  0.222222  ...  0.333333  0.166667  0.285714   \n",
       "108  0.000000  0.444444  0.111111  ...  0.000000  0.000000  0.000000   \n",
       "109  0.428571  0.333333  0.444444  ...  0.000000  0.000000  0.071429   \n",
       "110  0.428571  0.777778  0.555556  ...  1.000000  0.375000  0.785714   \n",
       "111  0.142857  0.444444  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "112  0.000000  0.444444  0.111111  ...  0.333333  0.041667  0.142857   \n",
       "113  0.000000  0.444444  0.111111  ...  0.000000  0.041667  0.142857   \n",
       "114  0.142857  0.333333  0.222222  ...  0.250000  0.166667  0.285714   \n",
       "115  0.428571  1.000000  0.333333  ...  1.000000  0.166667  0.571429   \n",
       "116  0.142857  0.333333  0.222222  ...  0.000000  0.041667  0.071429   \n",
       "117  0.285714  0.333333  0.333333  ...  0.333333  0.166667  0.285714   \n",
       "118  0.142857  1.000000  0.333333  ...  0.250000  0.375000  1.000000   \n",
       "119  0.142857  0.444444  0.000000  ...  0.000000  0.041667  0.071429   \n",
       "120  0.142857  0.333333  0.222222  ...  0.000000  0.166667  0.214286   \n",
       "121  0.142857  0.444444  0.111111  ...  0.000000  0.041667  0.071429   \n",
       "122  0.142857  0.777778  1.000000  ...  0.750000  1.000000  1.000000   \n",
       "123  0.000000  0.333333  0.222222  ...  0.000000  0.000000  0.000000   \n",
       "124  0.571429  0.444444  0.111111  ...  0.000000  0.000000  0.071429   \n",
       "125  0.428571  0.555556  1.000000  ...  1.000000  0.583333  1.000000   \n",
       "126  0.142857  0.333333  0.222222  ...  0.333333  0.166667  0.285714   \n",
       "127  0.142857  0.444444  0.000000  ...  0.000000  0.083333  0.071429   \n",
       "128  0.000000  0.444444  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "129  0.142857  0.333333  0.222222  ...  0.000000  0.166667  0.285714   \n",
       "130  0.142857  0.444444  0.111111  ...  0.000000  0.083333  0.000000   \n",
       "131  0.285714  0.333333  0.444444  ...  0.000000  0.125000  0.285714   \n",
       "132  0.428571  0.333333  0.333333  ...  0.000000  0.125000  0.142857   \n",
       "133  0.142857  0.333333  0.444444  ...  0.000000  0.083333  0.071429   \n",
       "134  0.142857  0.444444  0.000000  ...  0.000000  0.041667  0.142857   \n",
       "135  0.142857  0.444444  0.111111  ...  0.000000  0.000000  0.000000   \n",
       "136  0.142857  0.333333  0.333333  ...  0.000000  0.041667  0.000000   \n",
       "\n",
       "          P21   P22       P23       P28       P29   P30       P31  \n",
       "0    0.000000  0.50  0.083333  0.086957  0.400000  0.20  0.200000  \n",
       "1    0.000000  0.50  0.041667  0.173913  0.400000  0.00  0.000000  \n",
       "2    0.000000  0.00  0.000000  0.000000  0.400000  0.00  0.000000  \n",
       "3    0.357143  0.00  0.375000  0.130435  1.000000  1.00  0.800000  \n",
       "4    0.000000  0.25  0.000000  0.000000  0.400000  0.20  0.066667  \n",
       "5    0.142857  0.00  0.166667  0.565217  0.666667  0.00  0.000000  \n",
       "6    0.000000  0.25  0.000000  0.000000  0.400000  0.16  0.333333  \n",
       "7    0.071429  0.75  0.041667  0.173913  0.266667  0.00  0.000000  \n",
       "8    0.000000  0.00  0.000000  0.086957  0.400000  0.16  0.333333  \n",
       "9    0.142857  0.00  0.375000  0.347826  0.333333  0.00  0.000000  \n",
       "10   1.000000  0.50  0.791667  0.782609  0.333333  0.00  0.000000  \n",
       "11   0.000000  0.00  0.083333  0.173913  0.400000  0.20  0.333333  \n",
       "12   0.000000  0.25  0.041667  0.000000  0.400000  0.00  0.000000  \n",
       "13   0.000000  0.25  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "14   0.000000  0.50  0.041667  0.086957  0.400000  0.00  0.000000  \n",
       "15   0.142857  0.25  0.166667  0.565217  1.000000  0.20  1.000000  \n",
       "16   0.000000  0.00  0.000000  0.086957  0.266667  0.00  0.000000  \n",
       "17   0.000000  0.00  0.000000  0.000000  0.133333  0.00  0.000000  \n",
       "18   0.000000  0.75  0.041667  0.086957  0.400000  0.12  0.333333  \n",
       "19   0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "20   0.000000  0.00  0.166667  0.000000  0.400000  0.20  0.066667  \n",
       "21   0.000000  0.50  0.000000  0.173913  0.133333  0.00  0.000000  \n",
       "22   0.142857  0.50  0.375000  0.565217  1.000000  0.00  0.000000  \n",
       "23   0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "24   0.071429  0.25  0.083333  0.173913  0.266667  0.20  0.333333  \n",
       "25   0.071429  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "26   0.071429  0.50  0.041667  0.173913  0.400000  0.20  0.333333  \n",
       "27   0.285714  1.00  0.166667  0.260870  0.400000  0.00  0.000000  \n",
       "28   0.071429  0.75  0.083333  0.260870  0.266667  0.12  0.333333  \n",
       "29   0.000000  0.00  0.000000  0.000000  0.400000  0.00  0.000000  \n",
       "..        ...   ...       ...       ...       ...   ...       ...  \n",
       "107  0.142857  0.50  0.166667  0.173913  0.133333  0.20  0.333333  \n",
       "108  0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "109  0.000000  0.00  0.000000  0.173913  0.266667  0.00  0.000000  \n",
       "110  0.357143  0.00  0.375000  0.347826  1.000000  0.60  0.200000  \n",
       "111  0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "112  0.071429  0.25  0.000000  0.173913  0.400000  0.12  0.133333  \n",
       "113  0.000000  0.25  0.000000  0.086957  0.266667  0.00  0.000000  \n",
       "114  0.214286  1.00  0.166667  0.260870  0.133333  0.20  0.200000  \n",
       "115  0.142857  0.25  0.166667  0.347826  1.000000  1.00  1.000000  \n",
       "116  0.000000  0.00  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "117  0.214286  0.25  0.041667  0.173913  0.133333  0.12  0.200000  \n",
       "118  0.142857  0.75  0.166667  0.782609  0.666667  1.00  0.400000  \n",
       "119  0.071429  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "120  0.071429  0.25  0.083333  0.086957  0.400000  0.00  0.000000  \n",
       "121  0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "122  0.571429  1.00  0.583333  1.000000  0.333333  1.00  1.000000  \n",
       "123  0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "124  0.071429  0.00  0.041667  0.086957  0.400000  0.00  0.000000  \n",
       "125  0.571429  0.25  1.000000  0.347826  1.000000  0.80  0.600000  \n",
       "126  0.071429  0.00  0.125000  0.086957  0.400000  0.20  0.333333  \n",
       "127  0.000000  0.25  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "128  0.000000  0.00  0.000000  0.173913  0.266667  0.00  0.000000  \n",
       "129  0.214286  1.00  0.166667  0.260870  0.133333  0.00  0.000000  \n",
       "130  0.000000  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "131  0.000000  0.25  0.000000  0.173913  0.266667  0.00  0.000000  \n",
       "132  0.071429  0.00  0.000000  0.086957  0.400000  0.00  0.000000  \n",
       "133  0.071429  0.00  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "134  0.000000  0.25  0.041667  0.086957  0.400000  0.00  0.000000  \n",
       "135  0.000000  0.00  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "136  0.000000  0.00  0.000000  0.173913  0.400000  0.00  0.000000  \n",
       "\n",
       "[137 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2428353 ],\n",
       "       [0.31127619],\n",
       "       [0.04882222],\n",
       "       [0.0822578 ],\n",
       "       [0.17074639],\n",
       "       [0.20852076],\n",
       "       [0.21657142],\n",
       "       [0.18017602],\n",
       "       [0.20502576],\n",
       "       [0.23153831],\n",
       "       [0.13992858],\n",
       "       [0.21628754],\n",
       "       [0.03152865],\n",
       "       [0.19722124],\n",
       "       [0.04578767],\n",
       "       [0.1115566 ],\n",
       "       [1.        ],\n",
       "       [0.38085015],\n",
       "       [0.22578532],\n",
       "       [0.04701897],\n",
       "       [0.23593297],\n",
       "       [0.        ],\n",
       "       [0.1513024 ],\n",
       "       [0.09970298],\n",
       "       [0.41808299],\n",
       "       [0.14173404],\n",
       "       [0.06025507],\n",
       "       [0.2310557 ],\n",
       "       [0.19173245],\n",
       "       [0.12390206],\n",
       "       [0.10019529],\n",
       "       [0.04899825],\n",
       "       [0.11387535],\n",
       "       [0.0658504 ],\n",
       "       [0.15910956],\n",
       "       [0.14848783],\n",
       "       [0.1012773 ],\n",
       "       [0.08577188],\n",
       "       [0.2324804 ],\n",
       "       [0.1438602 ],\n",
       "       [0.3066044 ],\n",
       "       [0.18355283],\n",
       "       [0.20501272],\n",
       "       [0.08533828],\n",
       "       [0.16791365],\n",
       "       [0.14034643],\n",
       "       [0.16719019],\n",
       "       [0.3620819 ],\n",
       "       [0.32630029],\n",
       "       [0.40334201],\n",
       "       [0.05425267],\n",
       "       [0.11447475],\n",
       "       [0.03307051],\n",
       "       [0.23968191],\n",
       "       [0.18881668],\n",
       "       [0.31224896],\n",
       "       [0.06689273],\n",
       "       [0.11370891],\n",
       "       [0.09999203],\n",
       "       [0.13212853],\n",
       "       [0.108648  ],\n",
       "       [0.1725719 ],\n",
       "       [0.22301863],\n",
       "       [0.02533085],\n",
       "       [0.07555814],\n",
       "       [0.03268436],\n",
       "       [0.03948122],\n",
       "       [0.1565133 ],\n",
       "       [0.14486661],\n",
       "       [0.12414425],\n",
       "       [0.15274095],\n",
       "       [0.16102571],\n",
       "       [0.07416293],\n",
       "       [0.11850374],\n",
       "       [0.23458952],\n",
       "       [0.83027642],\n",
       "       [0.18550387],\n",
       "       [0.04070573],\n",
       "       [0.14673337],\n",
       "       [0.27839175],\n",
       "       [0.13897042],\n",
       "       [0.15726194],\n",
       "       [0.14329089],\n",
       "       [0.25968108],\n",
       "       [0.16717914],\n",
       "       [0.34211454],\n",
       "       [0.1186987 ],\n",
       "       [0.2564678 ],\n",
       "       [0.04720029],\n",
       "       [0.06548787],\n",
       "       [0.12273093],\n",
       "       [0.05033555],\n",
       "       [0.30368976],\n",
       "       [0.12190649],\n",
       "       [0.14039145],\n",
       "       [0.00650394],\n",
       "       [0.2837512 ],\n",
       "       [0.29896514],\n",
       "       [0.06442091],\n",
       "       [0.66993626],\n",
       "       [0.45842715],\n",
       "       [0.19456476],\n",
       "       [0.08562981],\n",
       "       [0.17682805],\n",
       "       [0.17888853],\n",
       "       [0.08854019],\n",
       "       [0.20159002],\n",
       "       [0.1131602 ],\n",
       "       [0.13050698],\n",
       "       [0.16549208],\n",
       "       [0.09727769],\n",
       "       [0.09937953],\n",
       "       [0.14203646],\n",
       "       [0.05106748],\n",
       "       [0.16205067],\n",
       "       [0.20127789],\n",
       "       [0.41757153],\n",
       "       [0.04684918],\n",
       "       [0.03763161],\n",
       "       [0.14180941],\n",
       "       [0.15731305],\n",
       "       [0.12375033],\n",
       "       [0.16912511],\n",
       "       [0.16788415],\n",
       "       [0.14342627],\n",
       "       [0.19575799],\n",
       "       [0.15451924],\n",
       "       [0.34735418],\n",
       "       [0.06653181],\n",
       "       [0.15042452],\n",
       "       [0.12003379],\n",
       "       [0.11051606],\n",
       "       [0.25005158],\n",
       "       [0.43742135],\n",
       "       [0.07521334],\n",
       "       [0.32715487],\n",
       "       [0.28108867]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_new,y_new,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=mod.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2329334595163991"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver':['sgd'],\n",
    "              'alpha' :[.0001,.001,.01],\n",
    "              'learning_rate' :['invscaling'],\n",
    "              'learning_rate_init' : [0.0001,.001,0.01]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=GridSearchCV(mod,param_grid,verbose=2,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_new,y_new,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.2s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.2s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.2s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=logistic, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.1s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.2s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.3s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.3s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=tanh, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.2s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.0001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.1s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.001, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.0001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.3s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.1s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.001, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n",
      "[CV] activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd \n",
      "[CV]  activation=relu, alpha=0.01, learning_rate=invscaling, learning_rate_init=0.01, solver=sgd, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed:   10.9s finished\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'activation': ['logistic', 'tanh', 'relu'], 'solver': ['sgd'], 'alpha': [0.0001, 0.001, 0.01], 'learning_rate': ['invscaling'], 'learning_rate_init': [0.0001, 0.001, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'learning_rate': 'invscaling',\n",
       " 'learning_rate_init': 0.01,\n",
       " 'solver': 'sgd'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7158185898487343"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalmodel=opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=finalmodel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13242180686259622"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "lable=preprocessing.MinMaxScaler()\n",
    "new_test=lable.fit_transform(test)\n",
    "cols=test.columns\n",
    "test_new=pd.DataFrame(new_test,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P8</th>\n",
       "      <th>P11</th>\n",
       "      <th>...</th>\n",
       "      <th>P18</th>\n",
       "      <th>P19</th>\n",
       "      <th>P20</th>\n",
       "      <th>P21</th>\n",
       "      <th>P22</th>\n",
       "      <th>P23</th>\n",
       "      <th>P28</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.482143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.321429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.839286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.196429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>0.267857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>0.303571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>0.267857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>0.910714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City  City Group      Type        P1        P2        P3        P4  \\\n",
       "0      0.678571         1.0  0.333333  0.000000  0.461538  0.666667  0.363636   \n",
       "1      0.482143         1.0  0.666667  0.142857  0.461538  0.666667  0.363636   \n",
       "2      0.053571         0.0  0.333333  0.142857  0.461538  0.666667  0.363636   \n",
       "3      0.464286         1.0  0.666667  0.071429  0.461538  0.666667  0.363636   \n",
       "4      0.017857         1.0  0.333333  0.071429  0.461538  0.666667  0.363636   \n",
       "5      0.321429         1.0  0.333333  0.214286  0.538462  0.833333  0.363636   \n",
       "6      0.714286         1.0  0.333333  0.214286  0.153846  0.666667  0.363636   \n",
       "7      0.053571         0.0  0.666667  0.071429  0.615385  0.666667  0.545455   \n",
       "8      0.964286         0.0  0.666667  0.285714  0.461538  0.666667  0.363636   \n",
       "9      0.964286         0.0  0.666667  1.000000  1.000000  1.000000  0.181818   \n",
       "10     0.464286         1.0  0.666667  0.785714  1.000000  1.000000  0.727273   \n",
       "11     0.053571         0.0  0.333333  0.071429  0.615385  0.666667  0.363636   \n",
       "12     0.964286         0.0  0.333333  0.357143  0.538462  0.666667  0.545455   \n",
       "13     0.839286         1.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "14     0.071429         1.0  0.333333  0.214286  0.461538  0.666667  0.363636   \n",
       "15     0.053571         0.0  0.666667  0.071429  0.615385  0.666667  0.545455   \n",
       "16     0.964286         0.0  0.333333  0.142857  0.615385  0.833333  0.727273   \n",
       "17     0.642857         1.0  0.666667  0.357143  0.461538  0.833333  0.181818   \n",
       "18     0.053571         0.0  0.333333  0.000000  1.000000  1.000000  0.727273   \n",
       "19     0.464286         1.0  0.666667  0.571429  0.615385  0.666667  0.363636   \n",
       "20     0.964286         0.0  0.333333  0.142857  0.307692  0.833333  0.363636   \n",
       "21     0.250000         1.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "22     0.964286         0.0  0.666667  0.000000  0.000000  0.833333  0.363636   \n",
       "23     0.964286         0.0  0.333333  0.142857  0.615385  0.666667  0.363636   \n",
       "24     0.000000         1.0  0.333333  0.571429  0.615385  0.666667  0.545455   \n",
       "25     0.196429         1.0  0.333333  0.071429  0.461538  0.666667  0.363636   \n",
       "26     0.107143         1.0  0.333333  0.071429  0.153846  0.666667  0.363636   \n",
       "27     0.375000         1.0  0.333333  0.142857  0.615385  0.500000  0.363636   \n",
       "28     0.964286         0.0  0.333333  0.142857  0.461538  0.666667  0.363636   \n",
       "29     0.071429         1.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "...         ...         ...       ...       ...       ...       ...       ...   \n",
       "99970  0.267857         1.0  0.666667  0.071429  0.307692  0.666667  0.545455   \n",
       "99971  0.053571         0.0  0.333333  0.571429  0.615385  1.000000  1.000000   \n",
       "99972  0.107143         1.0  0.333333  0.214286  0.461538  0.500000  0.363636   \n",
       "99973  0.053571         0.0  0.333333  0.214286  0.461538  0.666667  0.181818   \n",
       "99974  0.964286         0.0  0.000000  0.214286  0.153846  0.000000  0.181818   \n",
       "99975  0.964286         0.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "99976  0.964286         0.0  0.333333  0.142857  0.615385  0.666667  0.363636   \n",
       "99977  0.964286         0.0  0.333333  0.285714  0.615385  0.666667  0.545455   \n",
       "99978  0.071429         1.0  0.666667  0.142857  0.615385  0.666667  0.545455   \n",
       "99979  0.053571         0.0  0.666667  0.571429  0.769231  1.000000  0.727273   \n",
       "99980  0.750000         1.0  0.333333  0.214286  0.615385  0.833333  0.545455   \n",
       "99981  0.964286         0.0  0.333333  0.214286  0.615385  0.833333  0.181818   \n",
       "99982  0.303571         1.0  0.333333  0.142857  0.307692  0.666667  0.181818   \n",
       "99983  0.642857         1.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "99984  0.285714         1.0  0.666667  0.142857  0.538462  1.000000  0.727273   \n",
       "99985  0.464286         1.0  0.333333  0.142857  0.461538  0.666667  0.363636   \n",
       "99986  0.267857         1.0  0.666667  0.071429  0.307692  0.666667  0.363636   \n",
       "99987  0.982143         0.0  0.666667  0.214286  0.615385  0.666667  0.181818   \n",
       "99988  0.625000         1.0  0.666667  0.000000  0.153846  0.500000  0.363636   \n",
       "99989  0.464286         1.0  0.333333  0.142857  0.461538  0.666667  0.363636   \n",
       "99990  0.964286         0.0  0.666667  0.142857  0.461538  0.666667  0.363636   \n",
       "99991  0.982143         0.0  0.666667  0.214286  0.461538  0.666667  0.181818   \n",
       "99992  0.964286         0.0  0.666667  0.071429  0.307692  0.666667  0.363636   \n",
       "99993  0.035714         1.0  0.333333  0.214286  0.615385  0.666667  0.363636   \n",
       "99994  0.910714         1.0  0.666667  0.142857  0.461538  0.666667  0.363636   \n",
       "99995  0.071429         1.0  0.333333  0.285714  0.615385  0.666667  0.363636   \n",
       "99996  0.678571         1.0  0.666667  0.000000  0.153846  0.666667  0.181818   \n",
       "99997  0.964286         0.0  0.666667  0.214286  0.615385  0.666667  0.363636   \n",
       "99998  0.964286         0.0  0.333333  0.785714  1.000000  1.000000  0.727273   \n",
       "99999  0.964286         0.0  0.666667  0.071429  0.615385  0.666667  0.363636   \n",
       "\n",
       "        P5        P8       P11  ...       P18       P19       P20       P21  \\\n",
       "0      0.0  0.333333  0.444444  ...  0.000000  0.166667  0.285714  0.142857   \n",
       "1      0.2  0.222222  0.111111  ...  0.000000  0.166667  0.285714  0.142857   \n",
       "2      0.2  0.333333  0.333333  ...  0.000000  0.166667  0.285714  0.285714   \n",
       "3      0.2  0.333333  0.222222  ...  0.266667  0.125000  0.214286  0.142857   \n",
       "4      0.0  0.333333  0.222222  ...  0.000000  0.000000  0.285714  0.142857   \n",
       "5      0.2  0.444444  0.111111  ...  0.000000  0.041667  0.285714  0.142857   \n",
       "6      0.2  0.333333  0.222222  ...  0.000000  0.166667  0.285714  0.071429   \n",
       "7      0.2  0.333333  0.111111  ...  0.000000  0.166667  0.214286  0.071429   \n",
       "8      0.0  0.333333  0.111111  ...  0.266667  0.083333  0.285714  0.000000   \n",
       "9      0.6  0.444444  0.000000  ...  0.600000  1.000000  1.000000  0.000000   \n",
       "10     0.6  0.111111  0.000000  ...  0.266667  0.791667  0.142857  0.071429   \n",
       "11     0.2  0.333333  0.444444  ...  0.066667  0.166667  0.000000  0.000000   \n",
       "12     0.2  0.555556  0.444444  ...  0.000000  0.166667  0.285714  0.357143   \n",
       "13     0.2  0.333333  0.444444  ...  0.000000  0.166667  0.285714  0.142857   \n",
       "14     0.0  0.444444  0.111111  ...  0.200000  0.166667  0.000000  0.071429   \n",
       "15     0.0  0.444444  0.111111  ...  0.266667  0.166667  0.214286  0.000000   \n",
       "16     0.6  0.222222  1.000000  ...  0.000000  0.166667  1.000000  1.000000   \n",
       "17     0.0  0.444444  0.111111  ...  0.000000  0.041667  0.785714  0.071429   \n",
       "18     0.2  0.777778  0.111111  ...  0.000000  0.375000  0.142857  1.000000   \n",
       "19     0.2  0.444444  0.333333  ...  0.200000  0.125000  0.285714  0.142857   \n",
       "20     0.2  0.333333  0.222222  ...  0.000000  0.125000  0.000000  0.000000   \n",
       "21     0.2  0.444444  0.000000  ...  0.000000  0.000000  0.285714  0.000000   \n",
       "22     0.2  0.333333  0.222222  ...  0.200000  0.041667  0.142857  0.071429   \n",
       "23     0.2  0.444444  0.444444  ...  0.000000  0.083333  0.285714  0.071429   \n",
       "24     0.0  0.333333  1.000000  ...  0.800000  0.166667  0.285714  0.142857   \n",
       "25     0.0  0.000000  0.444444  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "26     0.2  0.444444  0.222222  ...  0.000000  0.000000  0.285714  0.000000   \n",
       "27     0.2  0.444444  0.000000  ...  0.000000  0.083333  0.214286  0.071429   \n",
       "28     0.2  0.444444  0.222222  ...  0.000000  0.166667  0.000000  0.142857   \n",
       "29     0.0  0.444444  1.000000  ...  0.000000  0.083333  0.142857  0.000000   \n",
       "...    ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "99970  0.4  0.444444  0.000000  ...  0.200000  0.166667  0.000000  0.000000   \n",
       "99971  0.4  0.111111  1.000000  ...  0.000000  1.000000  1.000000  1.000000   \n",
       "99972  0.2  0.444444  0.000000  ...  0.000000  0.041667  0.285714  0.071429   \n",
       "99973  0.0  0.333333  0.333333  ...  0.000000  0.166667  0.285714  0.214286   \n",
       "99974  0.0  0.444444  0.222222  ...  0.000000  0.000000  0.000000  0.142857   \n",
       "99975  0.4  0.333333  0.000000  ...  0.333333  0.041667  0.000000  0.285714   \n",
       "99976  0.0  0.333333  0.222222  ...  0.000000  0.000000  0.285714  0.071429   \n",
       "99977  0.2  0.333333  0.444444  ...  0.000000  0.041667  0.071429  0.142857   \n",
       "99978  0.0  0.222222  0.444444  ...  0.000000  0.166667  0.285714  0.214286   \n",
       "99979  0.6  1.000000  1.000000  ...  0.000000  0.166667  0.785714  0.142857   \n",
       "99980  0.0  0.333333  0.000000  ...  0.000000  0.000000  0.285714  0.214286   \n",
       "99981  0.0  0.444444  0.000000  ...  0.266667  0.125000  0.285714  0.000000   \n",
       "99982  0.0  0.333333  0.000000  ...  0.000000  0.125000  0.000000  0.000000   \n",
       "99983  0.2  0.333333  0.333333  ...  0.000000  0.083333  0.285714  0.285714   \n",
       "99984  1.0  0.444444  0.000000  ...  0.000000  1.000000  0.071429  0.357143   \n",
       "99985  0.2  0.777778  0.555556  ...  0.000000  0.125000  0.285714  0.571429   \n",
       "99986  0.2  0.333333  0.444444  ...  0.200000  0.125000  0.214286  0.071429   \n",
       "99987  0.2  0.444444  0.111111  ...  0.266667  0.041667  0.214286  0.071429   \n",
       "99988  0.6  1.000000  0.333333  ...  0.800000  0.000000  0.285714  0.142857   \n",
       "99989  0.0  0.444444  0.222222  ...  0.000000  0.125000  0.000000  0.000000   \n",
       "99990  0.0  0.444444  0.111111  ...  0.266667  0.166667  0.142857  0.000000   \n",
       "99991  0.2  0.333333  0.444444  ...  0.200000  0.125000  0.285714  0.142857   \n",
       "99992  0.0  0.444444  0.000000  ...  0.266667  0.041667  0.142857  0.000000   \n",
       "99993  0.0  0.444444  0.111111  ...  0.000000  0.083333  0.142857  0.000000   \n",
       "99994  1.0  0.222222  0.444444  ...  0.200000  0.166667  0.285714  0.285714   \n",
       "99995  0.2  0.444444  0.333333  ...  0.000000  0.083333  0.000000  0.000000   \n",
       "99996  0.0  0.444444  0.111111  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "99997  0.0  0.222222  0.444444  ...  0.200000  0.083333  0.285714  0.214286   \n",
       "99998  0.6  1.000000  0.555556  ...  0.000000  0.791667  0.571429  0.142857   \n",
       "99999  0.2  0.444444  0.333333  ...  0.066667  0.166667  0.214286  0.000000   \n",
       "\n",
       "        P22       P23       P28   P29   P30       P31  \n",
       "0      0.00  0.125000  0.086957  0.30  0.00  0.000000  \n",
       "1      0.25  0.000000  0.000000  0.30  0.00  0.000000  \n",
       "2      1.00  0.166667  0.086957  0.30  0.00  0.000000  \n",
       "3      0.25  0.041667  0.086957  0.30  0.00  0.266667  \n",
       "4      0.00  0.000000  0.347826  0.30  0.00  0.000000  \n",
       "5      0.25  0.083333  0.086957  0.30  0.00  0.000000  \n",
       "6      0.25  0.083333  0.000000  0.30  0.12  0.333333  \n",
       "7      0.00  0.083333  0.173913  0.10  0.12  0.000000  \n",
       "8      1.00  0.041667  0.347826  0.10  0.00  0.266667  \n",
       "9      0.00  0.000000  0.000000  0.25  0.80  0.133333  \n",
       "10     0.25  0.000000  0.086957  0.50  0.00  0.000000  \n",
       "11     0.00  0.000000  0.086957  0.30  0.20  0.000000  \n",
       "12     1.00  0.083333  0.347826  0.00  0.00  0.000000  \n",
       "13     0.50  0.083333  0.347826  0.00  0.00  0.066667  \n",
       "14     0.00  0.000000  0.000000  0.30  0.00  0.066667  \n",
       "15     0.25  0.166667  0.173913  0.10  0.20  0.200000  \n",
       "16     0.50  0.166667  1.000000  0.25  0.00  0.000000  \n",
       "17     0.25  0.000000  0.173913  0.30  0.00  0.000000  \n",
       "18     0.00  0.166667  0.347826  0.20  0.00  0.200000  \n",
       "19     0.25  0.000000  0.173913  0.30  0.20  0.066667  \n",
       "20     0.00  0.000000  0.000000  0.30  0.00  0.066667  \n",
       "21     0.75  0.000000  0.173913  0.20  0.00  0.000000  \n",
       "22     0.00  0.000000  0.086957  0.30  0.16  0.333333  \n",
       "23     0.75  0.000000  0.173913  0.30  0.00  0.000000  \n",
       "24     1.00  0.041667  0.347826  0.30  0.00  0.800000  \n",
       "25     0.00  0.000000  0.086957  0.20  0.00  0.000000  \n",
       "26     0.00  0.000000  0.086957  0.30  0.00  0.000000  \n",
       "27     0.00  0.000000  0.173913  0.30  0.00  0.000000  \n",
       "28     0.50  0.000000  0.173913  0.30  0.00  0.000000  \n",
       "29     0.00  0.041667  0.173913  0.25  0.00  0.000000  \n",
       "...     ...       ...       ...   ...   ...       ...  \n",
       "99970  1.00  0.041667  0.347826  0.00  0.08  0.000000  \n",
       "99971  1.00  0.166667  0.086957  0.10  1.00  1.000000  \n",
       "99972  0.25  0.125000  0.086957  0.20  0.00  0.000000  \n",
       "99973  0.50  0.041667  0.260870  0.30  0.16  0.000000  \n",
       "99974  0.00  0.000000  0.260870  0.30  0.00  0.333333  \n",
       "99975  1.00  0.166667  0.086957  0.30  0.00  0.000000  \n",
       "99976  1.00  0.000000  0.260870  0.30  0.00  0.000000  \n",
       "99977  1.00  0.000000  0.347826  0.00  0.00  0.000000  \n",
       "99978  1.00  0.166667  0.347826  0.10  0.20  0.066667  \n",
       "99979  0.25  0.166667  0.347826  0.75  0.00  0.400000  \n",
       "99980  0.50  0.166667  0.173913  0.10  0.00  0.000000  \n",
       "99981  0.50  0.000000  0.173913  0.20  0.16  0.000000  \n",
       "99982  0.00  0.000000  0.000000  0.30  0.00  0.000000  \n",
       "99983  1.00  0.000000  0.086957  0.20  0.00  0.000000  \n",
       "99984  0.75  0.375000  0.782609  0.30  0.60  0.000000  \n",
       "99985  0.25  0.375000  0.086957  0.30  0.00  0.000000  \n",
       "99986  0.50  0.041667  0.086957  0.10  0.16  0.200000  \n",
       "99987  0.25  0.083333  0.173913  0.30  0.20  0.333333  \n",
       "99988  0.25  0.000000  0.000000  0.75  0.40  0.000000  \n",
       "99989  0.50  0.000000  0.086957  0.30  0.00  0.000000  \n",
       "99990  0.25  0.166667  0.086957  0.30  0.20  0.000000  \n",
       "99991  0.50  0.166667  0.086957  0.10  0.12  0.066667  \n",
       "99992  0.25  0.083333  0.000000  0.30  0.00  0.000000  \n",
       "99993  0.75  0.041667  0.173913  0.30  0.00  0.000000  \n",
       "99994  0.75  0.125000  0.347826  0.20  0.00  0.000000  \n",
       "99995  0.50  0.041667  0.086957  0.30  0.00  0.000000  \n",
       "99996  0.00  0.041667  0.000000  0.30  0.20  0.000000  \n",
       "99997  1.00  0.166667  0.260870  0.10  0.20  0.333333  \n",
       "99998  0.50  0.583333  0.565217  0.50  0.00  0.000000  \n",
       "99999  0.25  0.000000  0.347826  0.30  0.00  0.133333  \n",
       "\n",
       "[100000 rows x 23 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreed=finalmodel.predict(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20317619, 0.124012  , 0.24165477, ..., 0.21569306, 0.22303723,\n",
       "       0.21082239])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_inv = scalary.inverse_transform(ypreed.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.37786638],\n",
       "       [ 6.94467206],\n",
       "       [13.53266727],\n",
       "       ...,\n",
       "       [12.07881147],\n",
       "       [12.49008481],\n",
       "       [11.8060538 ]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsubneu=pd.DataFrame()\n",
    "finalsubneu['Id']=test['Id']\n",
    "finalsubneu['Prediction']=pred_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.377866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.944672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.532667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.201444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14.625212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8.181104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8.840538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>11.102508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9.841250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.603681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6.250014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>13.180168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>13.177779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13.677737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>13.617437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>10.885204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>19.695289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.463704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>22.534732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>7.256128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>8.178705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>13.273951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>8.792594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>11.958942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>32.925569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>15.744207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>11.867728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>11.565582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>10.184997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>21.216219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>99970</td>\n",
       "      <td>13.576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>99971</td>\n",
       "      <td>34.390007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>99972</td>\n",
       "      <td>11.856324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>99973</td>\n",
       "      <td>10.637929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>99974</td>\n",
       "      <td>15.847112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>99975</td>\n",
       "      <td>11.637977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>99976</td>\n",
       "      <td>9.954021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>99977</td>\n",
       "      <td>14.554992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>99978</td>\n",
       "      <td>15.471975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>99979</td>\n",
       "      <td>17.320291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>99980</td>\n",
       "      <td>3.261878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>99981</td>\n",
       "      <td>2.306060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>99982</td>\n",
       "      <td>9.453713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>99983</td>\n",
       "      <td>10.876608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99984</td>\n",
       "      <td>3.762619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99985</td>\n",
       "      <td>16.257530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99986</td>\n",
       "      <td>13.338367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99987</td>\n",
       "      <td>6.621264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>99988</td>\n",
       "      <td>14.689087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>99989</td>\n",
       "      <td>9.639068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>99990</td>\n",
       "      <td>3.508442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <td>99991</td>\n",
       "      <td>8.470239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <td>99992</td>\n",
       "      <td>3.339637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99993</th>\n",
       "      <td>99993</td>\n",
       "      <td>13.875004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99994</th>\n",
       "      <td>99994</td>\n",
       "      <td>17.413894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>14.540851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>3.603704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>12.078811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>12.490085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>11.806054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Prediction\n",
       "0          0   11.377866\n",
       "1          1    6.944672\n",
       "2          2   13.532667\n",
       "3          3   13.201444\n",
       "4          4   14.625212\n",
       "5          5    8.181104\n",
       "6          6    8.840538\n",
       "7          7   11.102508\n",
       "8          8    9.841250\n",
       "9          9    1.603681\n",
       "10        10    6.250014\n",
       "11        11   13.180168\n",
       "12        12   13.177779\n",
       "13        13   13.677737\n",
       "14        14   13.617437\n",
       "15        15   10.885204\n",
       "16        16   19.695289\n",
       "17        17    0.463704\n",
       "18        18   22.534732\n",
       "19        19    7.256128\n",
       "20        20    8.178705\n",
       "21        21   13.273951\n",
       "22        22    8.792594\n",
       "23        23   11.958942\n",
       "24        24   32.925569\n",
       "25        25   15.744207\n",
       "26        26   11.867728\n",
       "27        27   11.565582\n",
       "28        28   10.184997\n",
       "29        29   21.216219\n",
       "...      ...         ...\n",
       "99970  99970   13.576300\n",
       "99971  99971   34.390007\n",
       "99972  99972   11.856324\n",
       "99973  99973   10.637929\n",
       "99974  99974   15.847112\n",
       "99975  99975   11.637977\n",
       "99976  99976    9.954021\n",
       "99977  99977   14.554992\n",
       "99978  99978   15.471975\n",
       "99979  99979   17.320291\n",
       "99980  99980    3.261878\n",
       "99981  99981    2.306060\n",
       "99982  99982    9.453713\n",
       "99983  99983   10.876608\n",
       "99984  99984    3.762619\n",
       "99985  99985   16.257530\n",
       "99986  99986   13.338367\n",
       "99987  99987    6.621264\n",
       "99988  99988   14.689087\n",
       "99989  99989    9.639068\n",
       "99990  99990    3.508442\n",
       "99991  99991    8.470239\n",
       "99992  99992    3.339637\n",
       "99993  99993   13.875004\n",
       "99994  99994   17.413894\n",
       "99995  99995   14.540851\n",
       "99996  99996    3.603704\n",
       "99997  99997   12.078811\n",
       "99998  99998   12.490085\n",
       "99999  99999   11.806054\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalsubneu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalsubneu.to_csv('Final_sub_neural.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
